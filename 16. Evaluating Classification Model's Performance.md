# Evaluating Classification Model's Performance

### False Positives and False Negatives
As we know from logistic classifier intuition, <br>
For four random values of the independent variables will end up in terms of y (hat) / in terms of predicted value of dependent variable <br>
And anything below 50% line is considered "false" and "true" if otherwise.
<img src =https://user-images.githubusercontent.com/54764108/167260719-123bb148-e6f8-4e4b-8a97-d1778ad13ea9.png width = "500">


Now considering known results and comparing them with our predicted model:
<img src =https://user-images.githubusercontent.com/54764108/167260940-9b569604-0592-4268-a448-1da693a0c2cb.png width = "500"> <img src =https://user-images.githubusercontent.com/54764108/167261169-fc20476a-0c23-4b8e-bd3d-e91f8234ed0c.png width = "500"> 

So, we can conclude that the logistic regression made an error here <br>
1. Mistakes made at the top are called **"False Positive" (Type 1 error)**
2. Mistakes made at the bottom are called **"False Negative" (Type 2 error)**


* False positives are mild error because we just perdicted that "an event will happen" when in reality it does not. And its comparatively easier to rollback and rectify that mistake (Warning)<br>
* HOwever, False negatives are much worse in the sense that we predict "an event will not happen" when it actually does. And we may already taken measures according to such hypothesis which may not be easy to be rectified.

But both are significant error in terms of mathematical analysis and we simply cant ignore these.


### Confusion Matrix

<img src =https://user-images.githubusercontent.com/54764108/167261656-eb9f1031-6986-4ff7-ab89-afa5b691f32e.png width = "500">
so indices of the matrix define if the model is aligned with the actual result. [0][1] and [1][0] dimentions indicate the errors/mispredictions made by the model

#### Analysis
1. Accuracy rate = Correct / Total <br>
                 = 85 / 100 = 85 %
2. Error rate = Wrong / Total 
              = 15 / 100 = 15 %
