# Multiple Linear Regression

```
y = b0 + b1*xx1 + b2*x2 + ... bn*xn

x's -> independent var 
y   -> dependent var
```

### A caveat

Assumptions of Linear Regression
1. Linearity
2. Homoscedasticity
3. Multivariat normality
4. Independence of errors
5. Lack of multicollinearity

### Dummy Variable

![image](https://user-images.githubusercontent.com/54764108/164259457-63406031-6c40-4255-87a9-bdfd4c920e36.png)

#### trap:
![image](https://user-images.githubusercontent.com/54764108/164260206-762e3969-330e-44cb-b1e8-d6a34927c3e3.png)


### Building a Model
- All-in
- Backward Elimination
- Forward Selection
- Bidirectional Elimination
- Score comparison

### A. Backward Elimination

####  Step - 1
> select significant level to stay in the model (e.g. SL = 0.05)
####  Step - 2
> fit full model with all possible predictors
####  Step - 3
> consider the predictor with the highest p value<br>
  If P>SL go to step 4<br>
  else go to FIN
####  Step - 4
> remove the predictor
####  Step - 5
> fit model without the variable (potentially goto step 3)

#### FIN = Model is finished/ready



### B. Forward Selection

- select significant level to enter the model (e.g. SL = 0.05)
- fit all simple regression models y ~ xn select the one with the lowest P-value
####  Step - 3
> kepp this variable and fit all possible models with one extra predictor added to the one(s) you already have <br>
####  Step - 4
> consider the predictor with the lowest P-value. 
> if P < SL, go to step-3
> else go to FIN 

#### FIN = Keep the previous Model 



### C. Bidirectional Elimination

#### Step - 1
> select a significant level to enter and to stay in the model (e.g. SLENTER = 0.05, SLSTAY = 0.05)
####  Step - 2
> perform the next step of Forward elimination (new variables must have P<SLENTER to enter)
####  Step - 3
> perform all steps of backward elimination (old variables must have P<SLSTAY to stay)
####  Step - 4
> no new variables can enter and old variables can exit
#### FIN = Model is ready


### D. All possible models

#### Step - 1
> select criterion of goodness of fot(e.g. Akaike criterion)
####  Step - 2
> construct all possible regression models: 2^n - 1 total combinations
####  Step - 3
> select one with best criterion

#### FIN = Model is ready



