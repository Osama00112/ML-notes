# Naive Bayes

Let us consider the data points below:

<img src = https://user-images.githubusercontent.com/54764108/166111887-9354c4f5-c0dd-4ee5-83cc-0c730ce03379.png width = "500">

### Bayes' Theorem
P(A∣B) = P(A⋂B)/P(B) = P(B∣A) * P(A) / P(B)
 
## Plan of Attack
### Step 1
<img src = https://user-images.githubusercontent.com/54764108/166110875-1aff69f0-71c7-4bf0-9297-f30a3482827f.png width = "500">

Where X = features. In this case there are 2 features.

### Step 2
<img src = https://user-images.githubusercontent.com/54764108/166111985-14c12e71-9736-4c4c-82ee-0a3d697a57cb.png width = "500">

### Step 3

Finally we are going to compare our probabilities.

![image](https://user-images.githubusercontent.com/54764108/166112019-ed33680c-d96b-4cfb-a497-fc698fc32d28.png)



## According to the given data set:

## Step 1

### 1. Prior Probability
P(Walks) = Number of walkers / Total Observations <br>
P(Walks) = 10 / 30

### 2. Marginal Likelihood
First we are going to make a circle around our observation. <br>
Looking at all the points inside the circle, these points are "similar" in terms of features to the point that we had.<br>
Any point that falls in the vicinity is going to be deemed similar to the new data point.

![image](https://user-images.githubusercontent.com/54764108/166112357-52782386-8bb3-44e8-a94f-c3a1224ba1f1.png)

P(X) = Number of similar observation / Total observation <br>
P(X) = 4 /30 

### 3. Likelihood

![image](https://user-images.githubusercontent.com/54764108/166112472-89eaab79-178a-4b4d-91c6-98a15a35e634.png)

P(X | Walks) = Number of Similar Observations among those who walks / Total number of walkers <br>
P(X | Walks) = 3 / 10


### 4. Posterior Probability

P(Walks | X) = [ (3/10) * (10/30) ]/ (4/30) <br>
P(Walks | X) = 0.75

## Step 2

***Following similar procedure for drivers, we get***

P(Drives) = 20 / 30 <br>
P(X) = 4 /30 <br>
P(X | Drives) = 1 / 20 <br>

P(Drives | X) = 0.25

## Step 3

0.75 vs 0.25 <br>
0.75 > 0.25 <br>

its more likely for that person (data point) to walk <br>
Therefore that feature is going to be classified as "Walker"


### Importing library for naive bayes based model

```python
from sklearn.naive_bayes import GaussianNB
classifier = GaussianNB()
classifier.fit(X_train, y_train)
```
### confusion  matrix
![image](https://user-images.githubusercontent.com/54764108/166114463-8263e5c8-1f24-4f69-8bcd-834b4fc6620d.png)

total mispredictions = 7 + 3 = 10

### Visualizing data
```python
# Visualising the Training set results
from matplotlib.colors import ListedColormap
X_set, y_set = X_train, y_train
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),
                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
             alpha = 0.75, cmap = ListedColormap(('red', 'green')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],
                c = ListedColormap(('red', 'green'))(i), label = j)
plt.title('Naive bayes (Training set)')
plt.xlabel('Age')
plt.ylabel('Estimated Salary')
plt.legend()
plt.show()
```
![image](https://user-images.githubusercontent.com/54764108/166114276-6b9e4b16-17d8-48fd-9e3e-be60c5db029e.png)


```python
# Visualising the Test set results
from matplotlib.colors import ListedColormap
X_set, y_set = X_test, y_test
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),
                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
             alpha = 0.75, cmap = ListedColormap(('red', 'green')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],
                c = ListedColormap(('red', 'green'))(i), label = j)
plt.title('Naive Bayes (Test set)')
plt.xlabel('Age')
plt.ylabel('Estimated Salary')
plt.legend()
plt.show()
```

![image](https://user-images.githubusercontent.com/54764108/166114258-be92d469-d09c-45f0-a849-50ef075c53cd.png)
