# K-Nearest Neighbours

It is a non linear classifier. (logistic was linear classifier)

### Steps:
1. Choose the number "K" of neighbours
2. Take the K nearest neighbours of the new data point, according to the Euclidean distance
3. Among these K neighburs, count the number of data points in each category
4. Assign the new data point to the category where you counted the most neighbours

### Then model is ready

### Importing the KNN model
default parameters in KNN are selected in such a way that we are preventing "over-fitting"

```python
#Create classifier
from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p= 2)
classifier.fit(X_train,y_train)
```


**n_neighbours** = 'K' of KNN <br>
**metric** = distance metric used for the tree. default is 'minkowski'  <br>
**p** = power parameter for the 'minkowski' distance metric. 
 > p = 1 for manhattan_distance, p = 2 (default) for euclidean distance <br>

### Cofusion matrix:
![image](https://user-images.githubusercontent.com/54764108/165565384-f9cb956a-c23b-4adc-b711-bf5c4de2fac6.png)

total mis_prediction = 3 + 4 = 7

### Visualising the Training set results
```python
from matplotlib.colors import ListedColormap
X_set, y_set = X_train, y_train
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),
                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
             alpha = 0.75, cmap = ListedColormap(('red', 'green')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],
                c = ListedColormap(('red', 'green'))(i), label = j)
plt.title('Classifier (Training set)')
plt.xlabel('Age')
plt.ylabel('Estimated Salary')
plt.legend()
plt.show()
```

<img src = https://user-images.githubusercontent.com/54764108/165567566-49d77130-379e-4645-8582-fad47f811908.png width = "500">

#### Now with the test data
```python
from matplotlib.colors import ListedColormap
X_set, y_set = X_test, y_test
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),
                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
             alpha = 0.75, cmap = ListedColormap(('red', 'green')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],
                c = ListedColormap(('red', 'green'))(i), label = j)
plt.title('KNN Classifier (Test set)')
plt.xlabel('Age')
plt.ylabel('Estimated Salary')
plt.legend()
plt.show()
```
<img src = https://user-images.githubusercontent.com/54764108/165568623-536e10ce-8831-4bfe-a8f8-5270fcbce84b.png width = "500">
