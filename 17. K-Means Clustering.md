# K-Means Clustering

## K-Means
![image](https://user-images.githubusercontent.com/54764108/167300245-de36def3-67a9-4750-8f1d-c8383451c394.png)

Suppose we have a scattered  set of data points based on two variables. <br>
Can we identify certain groups in these data set? <br>
**K-Means** is a complex algorithm designed to find these groups.

* **Step 1:** Choose the number **K** of clusters
* **Step 2:** Select at random K points, the centroids(not necessarily from your dataset)
* **Step 3:** Assign each data point to the closest centroid => That forms K clusters
* **Step 4:** Compute and place the new centroid of each cluster
* **Step 5:** Reassign each data point to the new closest centroid. <br>
If any assignment took place, go to STEP 4, otherwise go to FIN.
* **FIN:** Model is ready.

### Example
<img src = https://user-images.githubusercontent.com/54764108/167300642-01e7356a-839f-4e9b-927f-79f3033e9b29.png width = "500" >

#### Step 1 : 
Let K = 2
#### Step 2 : Selecting random K = 2 points, the centroid
<img src = https://user-images.githubusercontent.com/54764108/167300721-7773cab1-c643-4ed1-8c8b-1be1ec90557f.png width = "500" >

#### Step 3 : Forming K = 2 clusters
<img src = https://user-images.githubusercontent.com/54764108/167300834-38d79cd9-ef55-4633-a9a2-ef6812eff625.png width = "400" > <img src = https://user-images.githubusercontent.com/54764108/167300819-18b4a8ef-c243-4ea9-a7d1-e9eefcd28283.png width = "400" >

#### Step 4 :
<img src = https://user-images.githubusercontent.com/54764108/167300963-f7b92282-b2ae-4995-9f40-faa1d48197b8.png  width = "400" > <img src = https://user-images.githubusercontent.com/54764108/167300982-e6b1f6a0-8f67-4cb4-87ea-d529627cb278.png  width = "400" > 

* We compute the center of gravity/mass of clusters and make new centroids and replace them with the old ones.

#### Step 5 : Reassignment
<img src = https://user-images.githubusercontent.com/54764108/167301119-df8464f4-d0d8-44f1-bd95-08503490dfeb.png  width = "400" > <img src = https://user-images.githubusercontent.com/54764108/167301137-6635f34f-c241-4080-ace2-3fc323a9861b.png  width = "400" > 

#### Repeating:
Iterative approaches until the algorithm converges to the final assignments.

<img src = https://user-images.githubusercontent.com/54764108/167301239-bf24313f-9558-4c40-8045-ce2f70afbf3f.png  width = "400" > <img src = https://user-images.githubusercontent.com/54764108/167301256-ab9ef2c3-3ca5-41d6-8a84-892fc01244f2.png  width = "400" > 


## Random Initialization Trap

<img src = https://user-images.githubusercontent.com/54764108/167301770-0733d2e5-72e5-42d2-8862-ff39aa499581.png  width = "400" > <img src = https://user-images.githubusercontent.com/54764108/167301894-d4f79857-77cf-4fb1-b4b1-4ae9977d34de.png  width = "400" >

* This is the true initialization

### In case of "Bad random initialization"
<img src = https://user-images.githubusercontent.com/54764108/167302071-6c92bba7-6df2-4556-bb7b-e40caa6a44fe.png  width = "400" > <img src = https://user-images.githubusercontent.com/54764108/167302124-b00dbc5b-3128-4a36-8b06-b5b1cd32969f.png  width = "400" >

* We have a situation / phenomenon where the selection of centroids at the "very start of algorithm" can potentially affect or dictate the outcome of the algorithm This is not a good thing as centroids are picked at random. 
* So, we need a modification of the K - means algorithm (K - Means++ Algorithm)
* We need to make sure the tools we are using are bypassing this trap.

### Choosing the "right" number of clusters

#### Example
From the previous data sets <br>
<img src = https://user-images.githubusercontent.com/54764108/167302501-25a1b3c2-c8fb-48d6-a377-0759483ea8a0.png width = "500">

And the metric to which we can identify the right number of clusters is as follows: <br>
* WCSS ( Within-Cluster Sum of Square )
* WCSS is the sum of squared distance between each point and the centroid in a cluster.
* This is the WCSS for 3 clusters above: <br>
![image](https://user-images.githubusercontent.com/54764108/167302629-febc83e2-87a3-48b1-af1e-4471c89ec3fd.png)

* For 1 cluster : The WCSS is quite large
<img src = https://user-images.githubusercontent.com/54764108/167302822-ba644e5e-d72b-4ce8-beda-531aaed9ed13.png width = "500">

* For 2 cluster : The WCSS decreases as unnecessary spaces are avoided
<img src = https://user-images.githubusercontent.com/54764108/167302888-669f088f-7cca-4f38-a37f-21dbe96bf859.png width = "500">

* So the limit is upto the total number of points. (WCSS = 0)
* It is a good metric but its constantly decreasing 

#### Optimality
<img src = https://user-images.githubusercontent.com/54764108/167303042-e677311b-42e0-4cf2-a6a2-aa489b25207e.png width = "500">

* AS we can see that the first two increases of clusters made a huge jump in the graph. after that the curve became somewhat flat.

#### Elbow Method

* We try to look for that "elbow" shape in our curve (WCSS vs clusters) where the change went from "quite substantial" to "not as substantial"

<img src = https://user-images.githubusercontent.com/54764108/167303176-90b313f1-457f-4dbb-8bba-53b5de5f9b03.png width = "500">








